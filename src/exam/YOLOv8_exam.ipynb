{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsdLIyxVCn0LXGhnk6OJ4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bj-noh/lecture_nlp/blob/master/src/example/YOLOv8_exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**\n",
        "\n",
        "Pip install ultralytics and dependencies and check software and hardware."
      ],
      "metadata": {
        "id": "AVqf3oAutdMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoraE0d77-RO",
        "outputId": "8c45dfd2-b661-4650-eeed-d91adfbb4aad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.28)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.2.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "import cv2\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdRvFvwvtMeX",
        "outputId": "31b565ac-0d69-4c97-974d-719f8349bde6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.8/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Predict**\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLOv8 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ],
      "metadata": {
        "id": "uM559JdDtos2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on an image with YOLOv8n\n",
        "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOXIej7utaBC",
        "outputId": "5c6f5fd0-393e-44e0-d7f9-c9d703671dee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Found https://ultralytics.com/images/zidane.jpg locally at zidane.jpg\n",
            "image 1/1 /content/zidane.jpg: 384x640 2 persons, 1 tie, 489.1ms\n",
            "Speed: 12.9ms preprocess, 489.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Val**\n",
        "Validate a model's accuracy on the [COCO](https://docs.ultralytics.com/datasets/detect/coco/) dataset's `val` or `test` splits. The latest YOLOv8 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used. See [YOLOv8 Val Docs](https://docs.ultralytics.com/modes/val/) for more information."
      ],
      "metadata": {
        "id": "eSiF7uPdt7WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpmPUa-VtadT",
        "outputId": "b6bf1227-9bbf-419c-e7ab-47a84c824408"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 780M/780M [00:07<00:00, 116MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace datasets/coco/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace datasets/coco/LICENSE? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace datasets/coco/images/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate YOLOv8n on COCO8 val\n",
        "!yolo val model=yolov8n.pt data=coco8.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swxrgDGktaj6",
        "outputId": "f4441817-c03c-4390-88b3-7de5b66b1a9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y\n",
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.70s/it]\n",
            "                   all          4         17      0.621      0.833      0.888       0.63\n",
            "                person          3         10      0.721        0.5      0.519      0.269\n",
            "                   dog          1          1       0.37          1      0.995      0.597\n",
            "                 horse          1          2      0.751          1      0.995      0.631\n",
            "              elephant          1          2      0.505        0.5      0.828      0.394\n",
            "              umbrella          1          1      0.564          1      0.995      0.995\n",
            "          potted plant          1          1      0.814          1      0.995      0.895\n",
            "Speed: 12.4ms preprocess, 389.2ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Train**\n",
        "\n",
        "Train YOLOv8 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLOv8 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ],
      "metadata": {
        "id": "vSe6k25XutJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train YOLOv8n on COCO8 for 3 epochs\n",
        "!yolo train model=yolov8n.pt data=coco8.yaml epochs=3 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcJtuFXRtap6",
        "outputId": "cf5b4a5d-ad53-43d1-be57-5d041206e935"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/3         0G       1.52      4.075      1.811         24        640: 100% 1/1 [00:06<00:00,  6.64s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.86s/it]\n",
            "                   all          4         17      0.605       0.87      0.888      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/3         0G     0.8071      3.832      1.239         11        640: 100% 1/1 [00:04<00:00,  4.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.54s/it]\n",
            "                   all          4         17      0.557      0.833      0.874      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/3         0G     0.9564      2.496      1.297         24        640: 100% 1/1 [00:03<00:00,  3.97s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.34s/it]\n",
            "                   all          4         17       0.54      0.833      0.872      0.621\n",
            "\n",
            "3 epochs completed in 0.010 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.16s/it]\n",
            "                   all          4         17      0.541       0.86      0.872      0.621\n",
            "                person          3         10      0.639        0.5       0.51      0.285\n",
            "                   dog          1          1      0.316          1      0.995      0.597\n",
            "                 horse          1          2      0.628          1      0.995      0.648\n",
            "              elephant          1          2      0.386      0.658      0.745      0.303\n",
            "              umbrella          1          1      0.536          1      0.995      0.995\n",
            "          potted plant          1          1      0.742          1      0.995      0.895\n",
            "Speed: 3.6ms preprocess, 272.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Python Usage**\n",
        "\n",
        "YOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLOv8 Python Docs](https://docs.ultralytics.com/usage/python/)."
      ],
      "metadata": {
        "id": "4mQxvz8qvlug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco8.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y32LMAr4tawF",
        "outputId": "6d244254-b206-481d-c45b-6a965489b025"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train5/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3         0G       1.52      4.075      1.811         24        640: 100%|██████████| 1/1 [00:06<00:00,  6.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.605       0.87      0.888      0.618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3         0G     0.8071      3.832      1.239         11        640: 100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.557      0.833      0.874      0.611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3         0G     0.9564      2.496      1.297         24        640: 100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.54      0.833      0.872      0.621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.008 hours.\n",
            "Optimizer stripped from runs/detect/train5/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train5/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train5/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.541       0.86      0.872      0.621\n",
            "                person          3         10      0.639        0.5       0.51      0.285\n",
            "                   dog          1          1      0.316          1      0.995      0.597\n",
            "                 horse          1          2      0.628          1      0.995      0.648\n",
            "              elephant          1          2      0.386      0.658      0.745      0.303\n",
            "              umbrella          1          1      0.536          1      0.995      0.995\n",
            "          potted plant          1          1      0.742          1      0.995      0.895\n",
            "Speed: 3.1ms preprocess, 270.6ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Ultralytics YOLOv8.2.28 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.541       0.86      0.872      0.621\n",
            "                person          3         10      0.639        0.5       0.51      0.285\n",
            "                   dog          1          1      0.316          1      0.995      0.597\n",
            "                 horse          1          2      0.628          1      0.995      0.648\n",
            "              elephant          1          2      0.386      0.658      0.745      0.303\n",
            "              umbrella          1          1      0.536          1      0.995      0.995\n",
            "          potted plant          1          1      0.742          1      0.995      0.895\n",
            "Speed: 3.1ms preprocess, 255.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train52\u001b[0m\n",
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 336.8ms\n",
            "Speed: 5.5ms preprocess, 336.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tasks\n",
        "\n",
        "YOLOv8 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLOv8 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n",
        "\n",
        "<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n"
      ],
      "metadata": {
        "id": "r4twETTFv-Tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
      ],
      "metadata": {
        "id": "2xPtJftnwAeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.predict('https://ultralytics.com/images/bus.jpg', save=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj819Rvwta23",
        "outputId": "90b814e7-0ed3-46ea-ff57-453f629add2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 195.4ms\n",
            "Speed: 5.7ms preprocess, 195.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict7\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[122, 148, 172],\n",
              "         [120, 146, 170],\n",
              "         [125, 153, 177],\n",
              "         ...,\n",
              "         [157, 170, 184],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        [[127, 153, 177],\n",
              "         [124, 150, 174],\n",
              "         [127, 155, 179],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [159, 172, 186],\n",
              "         [159, 172, 186]],\n",
              " \n",
              "        [[128, 154, 178],\n",
              "         [126, 152, 176],\n",
              "         [126, 154, 178],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[185, 185, 191],\n",
              "         [182, 182, 188],\n",
              "         [179, 179, 185],\n",
              "         ...,\n",
              "         [114, 107, 112],\n",
              "         [115, 105, 111],\n",
              "         [116, 106, 112]],\n",
              " \n",
              "        [[157, 157, 163],\n",
              "         [180, 180, 186],\n",
              "         [185, 186, 190],\n",
              "         ...,\n",
              "         [107,  97, 103],\n",
              "         [102,  92,  98],\n",
              "         [108,  98, 104]],\n",
              " \n",
              "        [[112, 112, 118],\n",
              "         [160, 160, 166],\n",
              "         [169, 170, 174],\n",
              "         ...,\n",
              "         [ 99,  89,  95],\n",
              "         [ 96,  86,  92],\n",
              "         [102,  92,  98]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict7'\n",
              " speed: {'preprocess': 5.713224411010742, 'inference': 195.44506072998047, 'postprocess': 1.8494129180908203}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
      ],
      "metadata": {
        "id": "P49lB7rJwBLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "model.predict('https://ultralytics.com/images/bus.jpg', save=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQLqe0X3ta9p",
        "outputId": "1aaa6df1-5483-4788-f3c8-b535edbbf7c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 307.5ms\n",
            "Speed: 4.3ms preprocess, 307.5ms inference, 21.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[122, 148, 172],\n",
              "         [120, 146, 170],\n",
              "         [125, 153, 177],\n",
              "         ...,\n",
              "         [157, 170, 184],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        [[127, 153, 177],\n",
              "         [124, 150, 174],\n",
              "         [127, 155, 179],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [159, 172, 186],\n",
              "         [159, 172, 186]],\n",
              " \n",
              "        [[128, 154, 178],\n",
              "         [126, 152, 176],\n",
              "         [126, 154, 178],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[185, 185, 191],\n",
              "         [182, 182, 188],\n",
              "         [179, 179, 185],\n",
              "         ...,\n",
              "         [114, 107, 112],\n",
              "         [115, 105, 111],\n",
              "         [116, 106, 112]],\n",
              " \n",
              "        [[157, 157, 163],\n",
              "         [180, 180, 186],\n",
              "         [185, 186, 190],\n",
              "         ...,\n",
              "         [107,  97, 103],\n",
              "         [102,  92,  98],\n",
              "         [108,  98, 104]],\n",
              " \n",
              "        [[112, 112, 118],\n",
              "         [160, 160, 166],\n",
              "         [169, 170, 174],\n",
              "         ...,\n",
              "         [ 99,  89,  95],\n",
              "         [ 96,  86,  92],\n",
              "         [102,  92,  98]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/segment/predict'\n",
              " speed: {'preprocess': 4.333257675170898, 'inference': 307.4829578399658, 'postprocess': 21.175384521484375}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
      ],
      "metadata": {
        "id": "Hbp7Uk2JwDRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.predict('https://ultralytics.com/images/bus.jpg', save=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhzSrkh5tbEL",
        "outputId": "57a564dc-2df5-4bc7-db32-129c326a025f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 224x224 minibus 0.54, police_van 0.24, trolleybus 0.06, golfcart 0.02, streetcar 0.02, 35.5ms\n",
            "Speed: 20.0ms preprocess, 35.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'tench', 1: 'goldfish', 2: 'great_white_shark', 3: 'tiger_shark', 4: 'hammerhead', 5: 'electric_ray', 6: 'stingray', 7: 'cock', 8: 'hen', 9: 'ostrich', 10: 'brambling', 11: 'goldfinch', 12: 'house_finch', 13: 'junco', 14: 'indigo_bunting', 15: 'robin', 16: 'bulbul', 17: 'jay', 18: 'magpie', 19: 'chickadee', 20: 'water_ouzel', 21: 'kite', 22: 'bald_eagle', 23: 'vulture', 24: 'great_grey_owl', 25: 'European_fire_salamander', 26: 'common_newt', 27: 'eft', 28: 'spotted_salamander', 29: 'axolotl', 30: 'bullfrog', 31: 'tree_frog', 32: 'tailed_frog', 33: 'loggerhead', 34: 'leatherback_turtle', 35: 'mud_turtle', 36: 'terrapin', 37: 'box_turtle', 38: 'banded_gecko', 39: 'common_iguana', 40: 'American_chameleon', 41: 'whiptail', 42: 'agama', 43: 'frilled_lizard', 44: 'alligator_lizard', 45: 'Gila_monster', 46: 'green_lizard', 47: 'African_chameleon', 48: 'Komodo_dragon', 49: 'African_crocodile', 50: 'American_alligator', 51: 'triceratops', 52: 'thunder_snake', 53: 'ringneck_snake', 54: 'hognose_snake', 55: 'green_snake', 56: 'king_snake', 57: 'garter_snake', 58: 'water_snake', 59: 'vine_snake', 60: 'night_snake', 61: 'boa_constrictor', 62: 'rock_python', 63: 'Indian_cobra', 64: 'green_mamba', 65: 'sea_snake', 66: 'horned_viper', 67: 'diamondback', 68: 'sidewinder', 69: 'trilobite', 70: 'harvestman', 71: 'scorpion', 72: 'black_and_gold_garden_spider', 73: 'barn_spider', 74: 'garden_spider', 75: 'black_widow', 76: 'tarantula', 77: 'wolf_spider', 78: 'tick', 79: 'centipede', 80: 'black_grouse', 81: 'ptarmigan', 82: 'ruffed_grouse', 83: 'prairie_chicken', 84: 'peacock', 85: 'quail', 86: 'partridge', 87: 'African_grey', 88: 'macaw', 89: 'sulphur-crested_cockatoo', 90: 'lorikeet', 91: 'coucal', 92: 'bee_eater', 93: 'hornbill', 94: 'hummingbird', 95: 'jacamar', 96: 'toucan', 97: 'drake', 98: 'red-breasted_merganser', 99: 'goose', 100: 'black_swan', 101: 'tusker', 102: 'echidna', 103: 'platypus', 104: 'wallaby', 105: 'koala', 106: 'wombat', 107: 'jellyfish', 108: 'sea_anemone', 109: 'brain_coral', 110: 'flatworm', 111: 'nematode', 112: 'conch', 113: 'snail', 114: 'slug', 115: 'sea_slug', 116: 'chiton', 117: 'chambered_nautilus', 118: 'Dungeness_crab', 119: 'rock_crab', 120: 'fiddler_crab', 121: 'king_crab', 122: 'American_lobster', 123: 'spiny_lobster', 124: 'crayfish', 125: 'hermit_crab', 126: 'isopod', 127: 'white_stork', 128: 'black_stork', 129: 'spoonbill', 130: 'flamingo', 131: 'little_blue_heron', 132: 'American_egret', 133: 'bittern', 134: 'crane_(bird)', 135: 'limpkin', 136: 'European_gallinule', 137: 'American_coot', 138: 'bustard', 139: 'ruddy_turnstone', 140: 'red-backed_sandpiper', 141: 'redshank', 142: 'dowitcher', 143: 'oystercatcher', 144: 'pelican', 145: 'king_penguin', 146: 'albatross', 147: 'grey_whale', 148: 'killer_whale', 149: 'dugong', 150: 'sea_lion', 151: 'Chihuahua', 152: 'Japanese_spaniel', 153: 'Maltese_dog', 154: 'Pekinese', 155: 'Shih-Tzu', 156: 'Blenheim_spaniel', 157: 'papillon', 158: 'toy_terrier', 159: 'Rhodesian_ridgeback', 160: 'Afghan_hound', 161: 'basset', 162: 'beagle', 163: 'bloodhound', 164: 'bluetick', 165: 'black-and-tan_coonhound', 166: 'Walker_hound', 167: 'English_foxhound', 168: 'redbone', 169: 'borzoi', 170: 'Irish_wolfhound', 171: 'Italian_greyhound', 172: 'whippet', 173: 'Ibizan_hound', 174: 'Norwegian_elkhound', 175: 'otterhound', 176: 'Saluki', 177: 'Scottish_deerhound', 178: 'Weimaraner', 179: 'Staffordshire_bullterrier', 180: 'American_Staffordshire_terrier', 181: 'Bedlington_terrier', 182: 'Border_terrier', 183: 'Kerry_blue_terrier', 184: 'Irish_terrier', 185: 'Norfolk_terrier', 186: 'Norwich_terrier', 187: 'Yorkshire_terrier', 188: 'wire-haired_fox_terrier', 189: 'Lakeland_terrier', 190: 'Sealyham_terrier', 191: 'Airedale', 192: 'cairn', 193: 'Australian_terrier', 194: 'Dandie_Dinmont', 195: 'Boston_bull', 196: 'miniature_schnauzer', 197: 'giant_schnauzer', 198: 'standard_schnauzer', 199: 'Scotch_terrier', 200: 'Tibetan_terrier', 201: 'silky_terrier', 202: 'soft-coated_wheaten_terrier', 203: 'West_Highland_white_terrier', 204: 'Lhasa', 205: 'flat-coated_retriever', 206: 'curly-coated_retriever', 207: 'golden_retriever', 208: 'Labrador_retriever', 209: 'Chesapeake_Bay_retriever', 210: 'German_short-haired_pointer', 211: 'vizsla', 212: 'English_setter', 213: 'Irish_setter', 214: 'Gordon_setter', 215: 'Brittany_spaniel', 216: 'clumber', 217: 'English_springer', 218: 'Welsh_springer_spaniel', 219: 'cocker_spaniel', 220: 'Sussex_spaniel', 221: 'Irish_water_spaniel', 222: 'kuvasz', 223: 'schipperke', 224: 'groenendael', 225: 'malinois', 226: 'briard', 227: 'kelpie', 228: 'komondor', 229: 'Old_English_sheepdog', 230: 'Shetland_sheepdog', 231: 'collie', 232: 'Border_collie', 233: 'Bouvier_des_Flandres', 234: 'Rottweiler', 235: 'German_shepherd', 236: 'Doberman', 237: 'miniature_pinscher', 238: 'Greater_Swiss_Mountain_dog', 239: 'Bernese_mountain_dog', 240: 'Appenzeller', 241: 'EntleBucher', 242: 'boxer', 243: 'bull_mastiff', 244: 'Tibetan_mastiff', 245: 'French_bulldog', 246: 'Great_Dane', 247: 'Saint_Bernard', 248: 'Eskimo_dog', 249: 'malamute', 250: 'Siberian_husky', 251: 'dalmatian', 252: 'affenpinscher', 253: 'basenji', 254: 'pug', 255: 'Leonberg', 256: 'Newfoundland', 257: 'Great_Pyrenees', 258: 'Samoyed', 259: 'Pomeranian', 260: 'chow', 261: 'keeshond', 262: 'Brabancon_griffon', 263: 'Pembroke', 264: 'Cardigan', 265: 'toy_poodle', 266: 'miniature_poodle', 267: 'standard_poodle', 268: 'Mexican_hairless', 269: 'timber_wolf', 270: 'white_wolf', 271: 'red_wolf', 272: 'coyote', 273: 'dingo', 274: 'dhole', 275: 'African_hunting_dog', 276: 'hyena', 277: 'red_fox', 278: 'kit_fox', 279: 'Arctic_fox', 280: 'grey_fox', 281: 'tabby', 282: 'tiger_cat', 283: 'Persian_cat', 284: 'Siamese_cat', 285: 'Egyptian_cat', 286: 'cougar', 287: 'lynx', 288: 'leopard', 289: 'snow_leopard', 290: 'jaguar', 291: 'lion', 292: 'tiger', 293: 'cheetah', 294: 'brown_bear', 295: 'American_black_bear', 296: 'ice_bear', 297: 'sloth_bear', 298: 'mongoose', 299: 'meerkat', 300: 'tiger_beetle', 301: 'ladybug', 302: 'ground_beetle', 303: 'long-horned_beetle', 304: 'leaf_beetle', 305: 'dung_beetle', 306: 'rhinoceros_beetle', 307: 'weevil', 308: 'fly', 309: 'bee', 310: 'ant', 311: 'grasshopper', 312: 'cricket', 313: 'walking_stick', 314: 'cockroach', 315: 'mantis', 316: 'cicada', 317: 'leafhopper', 318: 'lacewing', 319: 'dragonfly', 320: 'damselfly', 321: 'admiral', 322: 'ringlet', 323: 'monarch', 324: 'cabbage_butterfly', 325: 'sulphur_butterfly', 326: 'lycaenid', 327: 'starfish', 328: 'sea_urchin', 329: 'sea_cucumber', 330: 'wood_rabbit', 331: 'hare', 332: 'Angora', 333: 'hamster', 334: 'porcupine', 335: 'fox_squirrel', 336: 'marmot', 337: 'beaver', 338: 'guinea_pig', 339: 'sorrel', 340: 'zebra', 341: 'hog', 342: 'wild_boar', 343: 'warthog', 344: 'hippopotamus', 345: 'ox', 346: 'water_buffalo', 347: 'bison', 348: 'ram', 349: 'bighorn', 350: 'ibex', 351: 'hartebeest', 352: 'impala', 353: 'gazelle', 354: 'Arabian_camel', 355: 'llama', 356: 'weasel', 357: 'mink', 358: 'polecat', 359: 'black-footed_ferret', 360: 'otter', 361: 'skunk', 362: 'badger', 363: 'armadillo', 364: 'three-toed_sloth', 365: 'orangutan', 366: 'gorilla', 367: 'chimpanzee', 368: 'gibbon', 369: 'siamang', 370: 'guenon', 371: 'patas', 372: 'baboon', 373: 'macaque', 374: 'langur', 375: 'colobus', 376: 'proboscis_monkey', 377: 'marmoset', 378: 'capuchin', 379: 'howler_monkey', 380: 'titi', 381: 'spider_monkey', 382: 'squirrel_monkey', 383: 'Madagascar_cat', 384: 'indri', 385: 'Indian_elephant', 386: 'African_elephant', 387: 'lesser_panda', 388: 'giant_panda', 389: 'barracouta', 390: 'eel', 391: 'coho', 392: 'rock_beauty', 393: 'anemone_fish', 394: 'sturgeon', 395: 'gar', 396: 'lionfish', 397: 'puffer', 398: 'abacus', 399: 'abaya', 400: 'academic_gown', 401: 'accordion', 402: 'acoustic_guitar', 403: 'aircraft_carrier', 404: 'airliner', 405: 'airship', 406: 'altar', 407: 'ambulance', 408: 'amphibian', 409: 'analog_clock', 410: 'apiary', 411: 'apron', 412: 'ashcan', 413: 'assault_rifle', 414: 'backpack', 415: 'bakery', 416: 'balance_beam', 417: 'balloon', 418: 'ballpoint', 419: 'Band_Aid', 420: 'banjo', 421: 'bannister', 422: 'barbell', 423: 'barber_chair', 424: 'barbershop', 425: 'barn', 426: 'barometer', 427: 'barrel', 428: 'barrow', 429: 'baseball', 430: 'basketball', 431: 'bassinet', 432: 'bassoon', 433: 'bathing_cap', 434: 'bath_towel', 435: 'bathtub', 436: 'beach_wagon', 437: 'beacon', 438: 'beaker', 439: 'bearskin', 440: 'beer_bottle', 441: 'beer_glass', 442: 'bell_cote', 443: 'bib', 444: 'bicycle-built-for-two', 445: 'bikini', 446: 'binder', 447: 'binoculars', 448: 'birdhouse', 449: 'boathouse', 450: 'bobsled', 451: 'bolo_tie', 452: 'bonnet', 453: 'bookcase', 454: 'bookshop', 455: 'bottlecap', 456: 'bow', 457: 'bow_tie', 458: 'brass', 459: 'brassiere', 460: 'breakwater', 461: 'breastplate', 462: 'broom', 463: 'bucket', 464: 'buckle', 465: 'bulletproof_vest', 466: 'bullet_train', 467: 'butcher_shop', 468: 'cab', 469: 'caldron', 470: 'candle', 471: 'cannon', 472: 'canoe', 473: 'can_opener', 474: 'cardigan', 475: 'car_mirror', 476: 'carousel', 477: \"carpenter's_kit\", 478: 'carton', 479: 'car_wheel', 480: 'cash_machine', 481: 'cassette', 482: 'cassette_player', 483: 'castle', 484: 'catamaran', 485: 'CD_player', 486: 'cello', 487: 'cellular_telephone', 488: 'chain', 489: 'chainlink_fence', 490: 'chain_mail', 491: 'chain_saw', 492: 'chest', 493: 'chiffonier', 494: 'chime', 495: 'china_cabinet', 496: 'Christmas_stocking', 497: 'church', 498: 'cinema', 499: 'cleaver', 500: 'cliff_dwelling', 501: 'cloak', 502: 'clog', 503: 'cocktail_shaker', 504: 'coffee_mug', 505: 'coffeepot', 506: 'coil', 507: 'combination_lock', 508: 'computer_keyboard', 509: 'confectionery', 510: 'container_ship', 511: 'convertible', 512: 'corkscrew', 513: 'cornet', 514: 'cowboy_boot', 515: 'cowboy_hat', 516: 'cradle', 517: 'crane_(machine)', 518: 'crash_helmet', 519: 'crate', 520: 'crib', 521: 'Crock_Pot', 522: 'croquet_ball', 523: 'crutch', 524: 'cuirass', 525: 'dam', 526: 'desk', 527: 'desktop_computer', 528: 'dial_telephone', 529: 'diaper', 530: 'digital_clock', 531: 'digital_watch', 532: 'dining_table', 533: 'dishrag', 534: 'dishwasher', 535: 'disk_brake', 536: 'dock', 537: 'dogsled', 538: 'dome', 539: 'doormat', 540: 'drilling_platform', 541: 'drum', 542: 'drumstick', 543: 'dumbbell', 544: 'Dutch_oven', 545: 'electric_fan', 546: 'electric_guitar', 547: 'electric_locomotive', 548: 'entertainment_center', 549: 'envelope', 550: 'espresso_maker', 551: 'face_powder', 552: 'feather_boa', 553: 'file', 554: 'fireboat', 555: 'fire_engine', 556: 'fire_screen', 557: 'flagpole', 558: 'flute', 559: 'folding_chair', 560: 'football_helmet', 561: 'forklift', 562: 'fountain', 563: 'fountain_pen', 564: 'four-poster', 565: 'freight_car', 566: 'French_horn', 567: 'frying_pan', 568: 'fur_coat', 569: 'garbage_truck', 570: 'gasmask', 571: 'gas_pump', 572: 'goblet', 573: 'go-kart', 574: 'golf_ball', 575: 'golfcart', 576: 'gondola', 577: 'gong', 578: 'gown', 579: 'grand_piano', 580: 'greenhouse', 581: 'grille', 582: 'grocery_store', 583: 'guillotine', 584: 'hair_slide', 585: 'hair_spray', 586: 'half_track', 587: 'hammer', 588: 'hamper', 589: 'hand_blower', 590: 'hand-held_computer', 591: 'handkerchief', 592: 'hard_disc', 593: 'harmonica', 594: 'harp', 595: 'harvester', 596: 'hatchet', 597: 'holster', 598: 'home_theater', 599: 'honeycomb', 600: 'hook', 601: 'hoopskirt', 602: 'horizontal_bar', 603: 'horse_cart', 604: 'hourglass', 605: 'iPod', 606: 'iron', 607: \"jack-o'-lantern\", 608: 'jean', 609: 'jeep', 610: 'jersey', 611: 'jigsaw_puzzle', 612: 'jinrikisha', 613: 'joystick', 614: 'kimono', 615: 'knee_pad', 616: 'knot', 617: 'lab_coat', 618: 'ladle', 619: 'lampshade', 620: 'laptop', 621: 'lawn_mower', 622: 'lens_cap', 623: 'letter_opener', 624: 'library', 625: 'lifeboat', 626: 'lighter', 627: 'limousine', 628: 'liner', 629: 'lipstick', 630: 'Loafer', 631: 'lotion', 632: 'loudspeaker', 633: 'loupe', 634: 'lumbermill', 635: 'magnetic_compass', 636: 'mailbag', 637: 'mailbox', 638: 'maillot_(tights)', 639: 'maillot_(tank_suit)', 640: 'manhole_cover', 641: 'maraca', 642: 'marimba', 643: 'mask', 644: 'matchstick', 645: 'maypole', 646: 'maze', 647: 'measuring_cup', 648: 'medicine_chest', 649: 'megalith', 650: 'microphone', 651: 'microwave', 652: 'military_uniform', 653: 'milk_can', 654: 'minibus', 655: 'miniskirt', 656: 'minivan', 657: 'missile', 658: 'mitten', 659: 'mixing_bowl', 660: 'mobile_home', 661: 'Model_T', 662: 'modem', 663: 'monastery', 664: 'monitor', 665: 'moped', 666: 'mortar', 667: 'mortarboard', 668: 'mosque', 669: 'mosquito_net', 670: 'motor_scooter', 671: 'mountain_bike', 672: 'mountain_tent', 673: 'mouse', 674: 'mousetrap', 675: 'moving_van', 676: 'muzzle', 677: 'nail', 678: 'neck_brace', 679: 'necklace', 680: 'nipple', 681: 'notebook', 682: 'obelisk', 683: 'oboe', 684: 'ocarina', 685: 'odometer', 686: 'oil_filter', 687: 'organ', 688: 'oscilloscope', 689: 'overskirt', 690: 'oxcart', 691: 'oxygen_mask', 692: 'packet', 693: 'paddle', 694: 'paddlewheel', 695: 'padlock', 696: 'paintbrush', 697: 'pajama', 698: 'palace', 699: 'panpipe', 700: 'paper_towel', 701: 'parachute', 702: 'parallel_bars', 703: 'park_bench', 704: 'parking_meter', 705: 'passenger_car', 706: 'patio', 707: 'pay-phone', 708: 'pedestal', 709: 'pencil_box', 710: 'pencil_sharpener', 711: 'perfume', 712: 'Petri_dish', 713: 'photocopier', 714: 'pick', 715: 'pickelhaube', 716: 'picket_fence', 717: 'pickup', 718: 'pier', 719: 'piggy_bank', 720: 'pill_bottle', 721: 'pillow', 722: 'ping-pong_ball', 723: 'pinwheel', 724: 'pirate', 725: 'pitcher', 726: 'plane', 727: 'planetarium', 728: 'plastic_bag', 729: 'plate_rack', 730: 'plow', 731: 'plunger', 732: 'Polaroid_camera', 733: 'pole', 734: 'police_van', 735: 'poncho', 736: 'pool_table', 737: 'pop_bottle', 738: 'pot', 739: \"potter's_wheel\", 740: 'power_drill', 741: 'prayer_rug', 742: 'printer', 743: 'prison', 744: 'projectile', 745: 'projector', 746: 'puck', 747: 'punching_bag', 748: 'purse', 749: 'quill', 750: 'quilt', 751: 'racer', 752: 'racket', 753: 'radiator', 754: 'radio', 755: 'radio_telescope', 756: 'rain_barrel', 757: 'recreational_vehicle', 758: 'reel', 759: 'reflex_camera', 760: 'refrigerator', 761: 'remote_control', 762: 'restaurant', 763: 'revolver', 764: 'rifle', 765: 'rocking_chair', 766: 'rotisserie', 767: 'rubber_eraser', 768: 'rugby_ball', 769: 'rule', 770: 'running_shoe', 771: 'safe', 772: 'safety_pin', 773: 'saltshaker', 774: 'sandal', 775: 'sarong', 776: 'sax', 777: 'scabbard', 778: 'scale', 779: 'school_bus', 780: 'schooner', 781: 'scoreboard', 782: 'screen', 783: 'screw', 784: 'screwdriver', 785: 'seat_belt', 786: 'sewing_machine', 787: 'shield', 788: 'shoe_shop', 789: 'shoji', 790: 'shopping_basket', 791: 'shopping_cart', 792: 'shovel', 793: 'shower_cap', 794: 'shower_curtain', 795: 'ski', 796: 'ski_mask', 797: 'sleeping_bag', 798: 'slide_rule', 799: 'sliding_door', 800: 'slot', 801: 'snorkel', 802: 'snowmobile', 803: 'snowplow', 804: 'soap_dispenser', 805: 'soccer_ball', 806: 'sock', 807: 'solar_dish', 808: 'sombrero', 809: 'soup_bowl', 810: 'space_bar', 811: 'space_heater', 812: 'space_shuttle', 813: 'spatula', 814: 'speedboat', 815: 'spider_web', 816: 'spindle', 817: 'sports_car', 818: 'spotlight', 819: 'stage', 820: 'steam_locomotive', 821: 'steel_arch_bridge', 822: 'steel_drum', 823: 'stethoscope', 824: 'stole', 825: 'stone_wall', 826: 'stopwatch', 827: 'stove', 828: 'strainer', 829: 'streetcar', 830: 'stretcher', 831: 'studio_couch', 832: 'stupa', 833: 'submarine', 834: 'suit', 835: 'sundial', 836: 'sunglass', 837: 'sunglasses', 838: 'sunscreen', 839: 'suspension_bridge', 840: 'swab', 841: 'sweatshirt', 842: 'swimming_trunks', 843: 'swing', 844: 'switch', 845: 'syringe', 846: 'table_lamp', 847: 'tank', 848: 'tape_player', 849: 'teapot', 850: 'teddy', 851: 'television', 852: 'tennis_ball', 853: 'thatch', 854: 'theater_curtain', 855: 'thimble', 856: 'thresher', 857: 'throne', 858: 'tile_roof', 859: 'toaster', 860: 'tobacco_shop', 861: 'toilet_seat', 862: 'torch', 863: 'totem_pole', 864: 'tow_truck', 865: 'toyshop', 866: 'tractor', 867: 'trailer_truck', 868: 'tray', 869: 'trench_coat', 870: 'tricycle', 871: 'trimaran', 872: 'tripod', 873: 'triumphal_arch', 874: 'trolleybus', 875: 'trombone', 876: 'tub', 877: 'turnstile', 878: 'typewriter_keyboard', 879: 'umbrella', 880: 'unicycle', 881: 'upright', 882: 'vacuum', 883: 'vase', 884: 'vault', 885: 'velvet', 886: 'vending_machine', 887: 'vestment', 888: 'viaduct', 889: 'violin', 890: 'volleyball', 891: 'waffle_iron', 892: 'wall_clock', 893: 'wallet', 894: 'wardrobe', 895: 'warplane', 896: 'washbasin', 897: 'washer', 898: 'water_bottle', 899: 'water_jug', 900: 'water_tower', 901: 'whiskey_jug', 902: 'whistle', 903: 'wig', 904: 'window_screen', 905: 'window_shade', 906: 'Windsor_tie', 907: 'wine_bottle', 908: 'wing', 909: 'wok', 910: 'wooden_spoon', 911: 'wool', 912: 'worm_fence', 913: 'wreck', 914: 'yawl', 915: 'yurt', 916: 'web_site', 917: 'comic_book', 918: 'crossword_puzzle', 919: 'street_sign', 920: 'traffic_light', 921: 'book_jacket', 922: 'menu', 923: 'plate', 924: 'guacamole', 925: 'consomme', 926: 'hot_pot', 927: 'trifle', 928: 'ice_cream', 929: 'ice_lolly', 930: 'French_loaf', 931: 'bagel', 932: 'pretzel', 933: 'cheeseburger', 934: 'hotdog', 935: 'mashed_potato', 936: 'head_cabbage', 937: 'broccoli', 938: 'cauliflower', 939: 'zucchini', 940: 'spaghetti_squash', 941: 'acorn_squash', 942: 'butternut_squash', 943: 'cucumber', 944: 'artichoke', 945: 'bell_pepper', 946: 'cardoon', 947: 'mushroom', 948: 'Granny_Smith', 949: 'strawberry', 950: 'orange', 951: 'lemon', 952: 'fig', 953: 'pineapple', 954: 'banana', 955: 'jackfruit', 956: 'custard_apple', 957: 'pomegranate', 958: 'hay', 959: 'carbonara', 960: 'chocolate_sauce', 961: 'dough', 962: 'meat_loaf', 963: 'pizza', 964: 'potpie', 965: 'burrito', 966: 'red_wine', 967: 'espresso', 968: 'cup', 969: 'eggnog', 970: 'alp', 971: 'bubble', 972: 'cliff', 973: 'coral_reef', 974: 'geyser', 975: 'lakeside', 976: 'promontory', 977: 'sandbar', 978: 'seashore', 979: 'valley', 980: 'volcano', 981: 'ballplayer', 982: 'groom', 983: 'scuba_diver', 984: 'rapeseed', 985: 'daisy', 986: \"yellow_lady's_slipper\", 987: 'corn', 988: 'acorn', 989: 'hip', 990: 'buckeye', 991: 'coral_fungus', 992: 'agaric', 993: 'gyromitra', 994: 'stinkhorn', 995: 'earthstar', 996: 'hen-of-the-woods', 997: 'bolete', 998: 'ear', 999: 'toilet_tissue'}\n",
              " obb: None\n",
              " orig_img: array([[[122, 148, 172],\n",
              "         [120, 146, 170],\n",
              "         [125, 153, 177],\n",
              "         ...,\n",
              "         [157, 170, 184],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        [[127, 153, 177],\n",
              "         [124, 150, 174],\n",
              "         [127, 155, 179],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [159, 172, 186],\n",
              "         [159, 172, 186]],\n",
              " \n",
              "        [[128, 154, 178],\n",
              "         [126, 152, 176],\n",
              "         [126, 154, 178],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[185, 185, 191],\n",
              "         [182, 182, 188],\n",
              "         [179, 179, 185],\n",
              "         ...,\n",
              "         [114, 107, 112],\n",
              "         [115, 105, 111],\n",
              "         [116, 106, 112]],\n",
              " \n",
              "        [[157, 157, 163],\n",
              "         [180, 180, 186],\n",
              "         [185, 186, 190],\n",
              "         ...,\n",
              "         [107,  97, 103],\n",
              "         [102,  92,  98],\n",
              "         [108,  98, 104]],\n",
              " \n",
              "        [[112, 112, 118],\n",
              "         [160, 160, 166],\n",
              "         [169, 170, 174],\n",
              "         ...,\n",
              "         [ 99,  89,  95],\n",
              "         [ 96,  86,  92],\n",
              "         [102,  92,  98]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: 'runs/classify/predict'\n",
              " speed: {'preprocess': 19.968748092651367, 'inference': 35.51745414733887, 'postprocess': 0.0934600830078125}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pose\n",
        "\n",
        "YOLOv8 _pose_ models use the `-pose` suffix, i.e. `yolov8n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
      ],
      "metadata": {
        "id": "Xe0jyRGVwFow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n pose model\n",
        "model.predict('https://ultralytics.com/images/bus.jpg', save=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W_oKLYItbLI",
        "outputId": "07729293-3afa-4a7f-c2dc-32c3f69d7fa0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 219.9ms\n",
            "Speed: 4.4ms preprocess, 219.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/pose/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: ultralytics.engine.results.Keypoints object\n",
              " masks: None\n",
              " names: {0: 'person'}\n",
              " obb: None\n",
              " orig_img: array([[[122, 148, 172],\n",
              "         [120, 146, 170],\n",
              "         [125, 153, 177],\n",
              "         ...,\n",
              "         [157, 170, 184],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        [[127, 153, 177],\n",
              "         [124, 150, 174],\n",
              "         [127, 155, 179],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [159, 172, 186],\n",
              "         [159, 172, 186]],\n",
              " \n",
              "        [[128, 154, 178],\n",
              "         [126, 152, 176],\n",
              "         [126, 154, 178],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[185, 185, 191],\n",
              "         [182, 182, 188],\n",
              "         [179, 179, 185],\n",
              "         ...,\n",
              "         [114, 107, 112],\n",
              "         [115, 105, 111],\n",
              "         [116, 106, 112]],\n",
              " \n",
              "        [[157, 157, 163],\n",
              "         [180, 180, 186],\n",
              "         [185, 186, 190],\n",
              "         ...,\n",
              "         [107,  97, 103],\n",
              "         [102,  92,  98],\n",
              "         [108,  98, 104]],\n",
              " \n",
              "        [[112, 112, 118],\n",
              "         [160, 160, 166],\n",
              "         [169, 170, 174],\n",
              "         ...,\n",
              "         [ 99,  89,  95],\n",
              "         [ 96,  86,  92],\n",
              "         [102,  92,  98]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/pose/predict'\n",
              " speed: {'preprocess': 4.383087158203125, 'inference': 219.85650062561035, 'postprocess': 1.5475749969482422}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Oriented Bounding Boxes (OBB)\n",
        "\n",
        "YOLOv8 _OBB_ models use the `-obb` suffix, i.e. `yolov8n-obb.pt` and are pretrained on the DOTA dataset. See [OBB Docs](https://docs.ultralytics.com/tasks/obb/) for full details."
      ],
      "metadata": {
        "id": "uE0Vq0iiwHgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-obb, train it on DOTA8 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-obb.pt')  # load a pretrained YOLOv8n OBB model\n",
        "model.predict('https://ultralytics.com/images/bus.jpg', save=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpyfWkDetbRc",
        "outputId": "9063fb7a-c692-41e5-96e9-8e7eec3ad9e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 1024x768 553.5ms\n",
            "Speed: 10.2ms preprocess, 553.5ms inference, 12.8ms postprocess per image at shape (1, 3, 1024, 768)\n",
            "Results saved to \u001b[1mruns/obb/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'plane', 1: 'ship', 2: 'storage tank', 3: 'baseball diamond', 4: 'tennis court', 5: 'basketball court', 6: 'ground track field', 7: 'harbor', 8: 'bridge', 9: 'large vehicle', 10: 'small vehicle', 11: 'helicopter', 12: 'roundabout', 13: 'soccer ball field', 14: 'swimming pool'}\n",
              " obb: ultralytics.engine.results.OBB object\n",
              " orig_img: array([[[122, 148, 172],\n",
              "         [120, 146, 170],\n",
              "         [125, 153, 177],\n",
              "         ...,\n",
              "         [157, 170, 184],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        [[127, 153, 177],\n",
              "         [124, 150, 174],\n",
              "         [127, 155, 179],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [159, 172, 186],\n",
              "         [159, 172, 186]],\n",
              " \n",
              "        [[128, 154, 178],\n",
              "         [126, 152, 176],\n",
              "         [126, 154, 178],\n",
              "         ...,\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185],\n",
              "         [158, 171, 185]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[185, 185, 191],\n",
              "         [182, 182, 188],\n",
              "         [179, 179, 185],\n",
              "         ...,\n",
              "         [114, 107, 112],\n",
              "         [115, 105, 111],\n",
              "         [116, 106, 112]],\n",
              " \n",
              "        [[157, 157, 163],\n",
              "         [180, 180, 186],\n",
              "         [185, 186, 190],\n",
              "         ...,\n",
              "         [107,  97, 103],\n",
              "         [102,  92,  98],\n",
              "         [108,  98, 104]],\n",
              " \n",
              "        [[112, 112, 118],\n",
              "         [160, 160, 166],\n",
              "         [169, 170, 174],\n",
              "         ...,\n",
              "         [ 99,  89,  95],\n",
              "         [ 96,  86,  92],\n",
              "         [102,  92,  98]]], dtype=uint8)\n",
              " orig_shape: (1080, 810)\n",
              " path: '/content/bus.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/obb/predict'\n",
              " speed: {'preprocess': 10.174751281738281, 'inference': 553.5147190093994, 'postprocess': 12.772560119628906}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}